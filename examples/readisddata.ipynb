{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script grabs out T2M data from the ISD station data and puts it in a netcdf file.\n",
    "The following data are chosen:\n",
    "- dates from 1979-2014\n",
    "- only stations with latitudes north of 30N\n",
    "- only stations with more than 20 years of data between 1979 and 2014.\n",
    "\n",
    "The 29th Feb is removed from leap years.\n",
    "T2M is set to nan when there is no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys \n",
    "import csv\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from CASutils import calendar_utils as cal\n",
    "from math import nan as nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify start year and end year for analysis.  Generate time axis for output and remove Feb 29th. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ystart=1979\n",
    "yend=2014\n",
    "nyears=yend-ystart+1\n",
    " \n",
    "# settting up output calendar dates\n",
    "timeout = pd.date_range(start=str(ystart)+\"-01-01\",end=str(yend)+\"-12-31\")\n",
    "# remove Feb 29th\n",
    "timeout = timeout[~((timeout.month == 2) & (timeout.day == 29))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up paths of data, inventory, isd-history file and output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "monstrings=['JAN','FEB','MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']\n",
    "datpath=\"/project/mojave/observations/ISD/global-summary-of-the-day/archive/\"\n",
    "statfile=\"/project/mojave/observations/ISD/global-summary-of-the-day/isd-history.txt\"\n",
    "inventfile=\"/project/mojave/observations/ISD/global-summary-of-the-day/isd-inventory.csv\"\n",
    "fileout=\"/project/cas/islas/python/ISD/T2M_ISD_30Nto90N_1979_2014.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up character locations of required columns from isd-history.txt.  Not sure there's a better way to parse this file that is space delimited but also with spaces in the titles and entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestart=[82,90] \n",
    "dateend=[91,99]\n",
    "latstr=[57,64]\n",
    "lonstr=[65,73]\n",
    "usafstr=[0,6]\n",
    "wbanstr=[7,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the isd-history file and grab out relevant station information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(statfile,\"r\")\n",
    "# skip header\n",
    "for i in range(22):\n",
    "    f.readline()\n",
    "\n",
    "#sys.exit()\n",
    "usaf=[] ; wban=[] ; dates=[] ; datee=[] ; lon=[] ; lat=[]\n",
    "count=0\n",
    "for line in f:\n",
    "    dates.append(line[datestart[0]:datestart[1]])\n",
    "    datee.append(line[dateend[0]:dateend[1]])\n",
    "    lon.append(line[lonstr[0]:lonstr[1]])\n",
    "    lat.append(line[latstr[0]:latstr[1]])\n",
    "    usaf.append(line[usafstr[0]:usafstr[1]])\n",
    "    wban.append(line[wbanstr[0]:wbanstr[1]])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dictionary containing station information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictstat=[{'wban': wban, 'usaf': usaf, 'lat': lat, 'lon':lon, 'dates':dates, 'datee':datee} for wban, usaf, lat, lon, dates, datee in zip (wban, usaf, lat, lon, dates, datee)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/cas/islas/miniconda3/envs/ecpaperenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "inventory = pd.read_csv(inventfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only stations that have data extending from 1979 to 2014 and have latitude greter than 30degN and have more than 20 years worth of data in that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuse=[]\n",
    "statname=[]\n",
    "usaf=[]\n",
    "wban=[]\n",
    "latstation=[]\n",
    "lonstation=[]\n",
    "for key in dictstat:\n",
    "    try:\n",
    "        latflt=float(key['lat'])\n",
    "    except:\n",
    "        latflt=-9999.\n",
    "        \n",
    "    try: \n",
    "        lonflt=float(key['lon'])\n",
    "    except:\n",
    "        lonflt=-9999.\n",
    "        \n",
    "    try:\n",
    "        usafval = int(key['usaf'])\n",
    "    except:\n",
    "        usafval = key['usaf']\n",
    "        \n",
    "    inventdat = inventory.loc[inventory['USAF']==usafval]\n",
    "    statyears = inventdat.loc[(inventdat['YEAR'] >= 1979) & (inventdat['YEAR'] <= 2014)]\n",
    "    statyears = statyears['YEAR']\n",
    "    \n",
    "    datebegflt = float(key['dates'])\n",
    "    dateendflt = float(key['datee'])\n",
    "    \n",
    "    # cut based on latitude and year start and year end and number of years of data\n",
    "    if ((latflt >= 30.) and (datebegflt < ystart*10000) and (dateendflt >= (yend*10000+1)) and (len(statyears) > 20)):        \n",
    "        statuse.append(key)\n",
    "        statname.append(key['usaf']+key['wban'])\n",
    "        usaf.append(key['usaf'])\n",
    "        wban.append(key['wban'])\n",
    "        latstation.append(latflt)\n",
    "        lonstation.append(lonflt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate dates for a non-leap year year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datevals=pd.date_range(start=\"1979-01-01\",end=\"1979-12-31\")\n",
    "m = np.array(datevals.month)\n",
    "mm = np.char.zfill(m.astype(str),2)\n",
    "d = np.array(datevals.day)\n",
    "dd = np.char.zfill(d.astype(str),2)\n",
    "datestrings=[mmm + \"-\" +  ddd  for  mmm, ddd in zip(mm, dd) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01001099999\n",
      "1:01004099999\n",
      "2:01008099999\n",
      "3:01010099999\n",
      "4:01017099999\n",
      "5:01023099999\n",
      "6:01025099999\n",
      "7:01028099999\n",
      "8:01033099999\n",
      "9:01035099999\n",
      "10:01041099999\n",
      "11:01043099999\n",
      "12:01045099999\n",
      "13:01046099999\n",
      "14:01047099999\n",
      "15:01049099999\n",
      "16:01052099999\n",
      "17:01055099999\n",
      "18:01057099999\n",
      "19:01059099999\n",
      "20:01062099999\n",
      "21:01065099999\n",
      "22:01074099999\n",
      "23:01078099999\n",
      "24:01083099999\n",
      "25:01088099999\n",
      "26:01089099999\n",
      "27:01092099999\n",
      "28:01098099999\n",
      "29:01102099999\n",
      "30:01112099999\n",
      "31:01115099999\n"
     ]
    }
   ],
   "source": [
    "t2m = np.empty([len(statname),nyears*365])\n",
    "t2m[:,:]=nan\n",
    "for istat in range(0,len(statname),1):\n",
    "    print(str(istat)+':'+statname[istat])\n",
    "\n",
    "    usafval = int(usaf[istat])\n",
    "    wbanval = int(wban[istat])\n",
    "    inventdat = inventory.loc[inventory['USAF']==usafval]\n",
    "    statyears = inventdat.loc[(inventdat['YEAR'] >= 1979) & (inventdat['YEAR'] <= 2014)]\n",
    "    statyears = statyears['YEAR']  \n",
    "\n",
    "    for iyear in range(ystart,yend+1,1):\n",
    "        if (iyear in statyears.astype(int).values):   \n",
    "            datesofyear=[str(iyear)+'-'+i for i in datestrings]\n",
    "            yearinvent = inventdat.loc[inventdat['YEAR'].astype(int) == iyear]\n",
    "            yearinvent = yearinvent.loc[yearinvent['WBAN']==wbanval]\n",
    "            #yearinvent = inventdat.where(inventdat['YEAR'].astype(int)==iyear).dropna(how='all')\n",
    "\n",
    "            # check there's enough data in the year\n",
    "            sumobs = 0.\n",
    "            for imon in monstrings:\n",
    "                sumobs = sumobs + np.array(yearinvent[imon])\n",
    "            \n",
    "            if (sumobs > 365): # only using the file if there's more then 365 obs going into the year (a bit arbitrary)\n",
    "            \n",
    "                fname=datpath+str(iyear)+\"/\"+statname[istat]+'.csv'\n",
    "\n",
    "                try:\n",
    "                    data = pd.read_csv(fname)\n",
    "                    date_data = data[['DATE','TEMP']]\n",
    "                    \n",
    "                    # remove Feb 29th\n",
    "                    date_data = date_data[~date_data['DATE'].isin([str(iyear)+'-02-29'])]\n",
    "                    \n",
    "                    alldates = [str(iyear)+'-'+i for i in datestrings]\n",
    "                    # assign indices to dates\n",
    "                    alldatesinds=dict() \n",
    "                    for i, j in enumerate(alldates):\n",
    "                        alldatesinds.setdefault(j, []).append(i)\n",
    "                        \n",
    "                    # find indices of all dates that are in data\n",
    "                    # and assign the relevant elements of t2m to the right place in the array\n",
    "                    res = [alldatesinds.get(i, [None]) for i in date_data['DATE']]\n",
    "                    t2m[istat,(iyear-ystart)*365+np.array(res).squeeze()] = date_data['TEMP']\n",
    "\n",
    "                except:\n",
    "                    t2m[istat,(iyear-ystart)*365:(iyear-ystart+1)*365] = nan            \n",
    "            else:\n",
    "                t2m[istat, (iyear-ystart)*365:(iyear-ystart+1)*365] = nan \n",
    "        else:\n",
    "            t2m[istat,(iyear-ystart)*365:(iyear-ystart+1)*365] = nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert to xarray data array and merge into a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mxr = xr.DataArray(t2m, coords=[statname, timeout], dims=['station','time'], name='t2m')\n",
    "lon = xr.DataArray(lonstation, name='lon', coords=[statname], dims=['station'])\n",
    "lat = xr.DataArray(latstation, name='lat', coords=[statname], dims=['station'])\n",
    "stationdat = xr.merge([t2mxr, lon,lat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationdat.to_netcdf(path=\"/project/cas/islas/savs/python/ISD/T2M_ISD_1979_2014.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ecpaperenv]",
   "language": "python",
   "name": "conda-env-ecpaperenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
